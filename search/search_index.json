{"config":{"lang":["fr"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Projet IFT3150: M\u00e9thode interpr\u00e9table par auto-encodeur creux pour l'encodage de l'activit\u00e9 c\u00e9r\u00e9brale IRMf","text":"<p>Th\u00e8mes: Neuro-imagerie, Science des donn\u00e9es, Apprentissage-machine Superviseur: Pierre Lune Bellec Collaborateurs: </p>"},{"location":"#informations-importantes","title":"Informations importantes","text":"<p>Dates importantes</p> <ul> <li>Description du projet : 16 mai 2025<ul> <li>Foire 1: Prototypage : 9-13 juin 2025</li> <li>Foire 2: Version beta : 14-18 juillet 2025</li> <li>Pr\u00e9sentation et rapport : 11-15 ao\u00fbt 2025</li> </ul> </li> </ul>"},{"location":"#equipe","title":"\u00c9quipe","text":"<ul> <li>Claud\u00e9ric DeRoy</li> </ul>"},{"location":"#description-du-projet","title":"Description du projet","text":"<ul> <li>The Algonauts Project 2025 est une comp\u00e9tition amicale internationale qui consiste en un d\u00e9fi o\u00f9 des chercheur(e)s doivent \u00e9laborer un mod\u00e8le d'encodage de l'activit\u00e9 c\u00e9r\u00e9brale humaine issu de stimuli multimodaux (i.e. stimulus visuel, auditif et langagier). Toutefois, les stimuli ne sont pas sous une forme utilisable pour un mod\u00e8le d'AM. Il faut donc extraire des stimuli des caract\u00e9ristiques qui pourront \u00eatre utilisable par un AM. Dans ce cas, les caract\u00e9ristiques extraitent sont volumineuses et il est donc pr\u00e9f\u00e9rable d'en r\u00e9duire la dimension le plus possible. L'algorithme de base pour effectuer cette r\u00e9duction de dimensionnalit\u00e9 est une Principal Component Analysis (PCA). Une fois la dimension effectue, les donn\u00e9es sont utilis\u00e9es avec les donn\u00e9es d'activit\u00e9 c\u00e9r\u00e9brale afin d'\u00e9laborer un encodeur de l'activit\u00e9 c\u00e9r\u00e9brale. Un des mod\u00e8les les plus utilis\u00e9s est le Ridge Regression (RR).</li> </ul>"},{"location":"#contexte","title":"Contexte","text":"<ul> <li>Depuis 2019, The Algonauts Project offre \u00e0 chaque ann\u00e9e un d\u00e9fi sous forme de projet afin de faciliter la coop\u00e9ration entre les chercheur(e)s en biologie et en apprentissage machine (AM). Cette ann\u00e9e, le d\u00e9fi est trouver un mod\u00e8le AM qui permet de bien encoder l'activit\u00e9 c\u00e9r\u00e9brale humain provenant de l'exposition \u00e0 des stimuli multimodaux (i.e. visuel, auditif et langagier).</li> </ul>"},{"location":"#problematique-ou-motivations","title":"Probl\u00e9matique ou motivations","text":"<ul> <li>La m\u00e9thode courament utilis\u00e9 pour r\u00e9duire la dimension des caract\u00e9ristiques extraites des stimuli multimodaux est la PCA. Malgr\u00e9 la r\u00e9duction de dimensionalit\u00e9 issu de la PCA, le RR obtenu contient des milliards de param\u00e8tres et est donc difficilement interpr\u00e9table et long \u00e0 entra\u00eener. </li> </ul>"},{"location":"#proposition-et-objectifs","title":"Proposition et objectifs","text":"<ul> <li>Nous voulons changer la PCA qui est le plus souvent utilis\u00e9 afin de r\u00e9duire la dimension des caract\u00e9ristiques extraite des stimuli multimodaux par un auto-encodeur \u00e0 matrice creuse. Ce mod\u00e8le permettrait d'obtenir une r\u00e9duction des caract\u00e9ristiques meilleure et donnerait des r\u00e9sultats plus interpr\u00e9table avec le RR.</li> </ul>"},{"location":"#echeancier","title":"\u00c9ch\u00e9ancier","text":"<p>Info</p> <p>Le suivi complet est disponible dans la page Suivi de projet.</p> Jalon (Milestone) Date pr\u00e9vue Livrable Statut Ouverture de projet 1 mai Proposition de projet \u2705 Termin\u00e9 Analyse des exigences 16 mai Document d'analyse \ud83d\udd04 En cours Prototype 1 23 mai Maquette + Flux d'activit\u00e9s \u23f3 \u00c0 venir Prototype 2 30 mai Prototype finale + Flux \u23f3 \u00c0 venir Architecture 30 mai Diagramme UML ou mod\u00e8le C4 \u23f3 \u00c0 venir Mod\u00e8le de donne\u00e9s 6 juin Diagramme UML ou entit\u00e9-association \u23f3 \u00c0 venir Revue de conception 6 juin Feedback encadrant + ajustements \u23f3 \u00c0 venir Impl\u00e9mentation v1 20 juin Application v1 \u23f3 \u00c0 venir Impl\u00e9mentation v2 + tests 11 juillet Application v2 + Tests \u23f3 \u00c0 venir Impl\u00e9mentation v3 1er ao\u00fbt Version finale \u23f3 \u00c0 venir Tests 11-31 juillet Plan + R\u00e9sultats interm\u00e9diaires \u23f3 \u00c0 venir \u00c9valuation finale 8 ao\u00fbt Analyse des r\u00e9sultats + Discussion \u23f3 \u00c0 venir Pr\u00e9sentation + Rapport 15 ao\u00fbt Pr\u00e9sentation + Rapport \u23f3 \u00c0 venir"},{"location":"analysis/","title":"\u00c9tudes pr\u00e9liminaires","text":""},{"location":"analysis/#analyse-du-probleme","title":"Analyse du probl\u00e8me","text":"<ul> <li>D\u00e9crire le probl\u00e8me \u00e0 r\u00e9soudre.</li> </ul>"},{"location":"analysis/#exigences","title":"Exigences","text":"<ul> <li>Lister les exigences fonctionnelles et non fonctionnelles.</li> </ul>"},{"location":"analysis/#recherche-de-solutions","title":"Recherche de solutions","text":"<ul> <li>Pr\u00e9senter les solutions existantes et justifier le choix retenu.</li> </ul>"},{"location":"analysis/#methodologie","title":"M\u00e9thodologie","text":""},{"location":"conception/","title":"Conception","text":""},{"location":"conception/#architecture","title":"Architecture","text":"<ul> <li>D\u00e9crire l'architecture du syst\u00e8me propos\u00e9.</li> </ul>"},{"location":"conception/#choix-technologiques","title":"Choix technologiques","text":"<ul> <li>Justifier les technologies et outils choisis.</li> </ul>"},{"location":"conception/#modeles-et-diagrammes","title":"Mod\u00e8les et diagrammes","text":"<ul> <li>Inclure des diagrammes UML, maquettes, etc.</li> </ul>"},{"location":"conception/#prototype","title":"Prototype","text":"<ul> <li>Inclure des diagrammes UML, maquettes, etc.</li> </ul>"},{"location":"evaluation/","title":"\u00c9valuation","text":""},{"location":"evaluation/#plan-de-test","title":"Plan de test","text":"<ul> <li>D\u00e9crire la strat\u00e9gie de test.</li> </ul>"},{"location":"evaluation/#criteres-devaluation","title":"Crit\u00e8res d'\u00e9valuation","text":"<ul> <li>Pr\u00e9senter les crit\u00e8res utilis\u00e9s pour \u00e9valuer le syst\u00e8me.</li> </ul>"},{"location":"evaluation/#analyse-des-resultats","title":"Analyse des r\u00e9sultats","text":"<ul> <li>Discuter des r\u00e9sultats obtenus lors des tests.</li> </ul>"},{"location":"references/","title":"R\u00e9f\u00e9rences","text":"<ul> <li> <p>Lister les ouvrages, articles et ressources acad\u00e9miques consult\u00e9s.</p> </li> <li> <p>Inclure des liens vers des sites web, outils ou technologies utilis\u00e9s.</p> </li> </ul>"},{"location":"resources/","title":"Resources","text":"<pre><code>graph TD\n    A[Start] --&gt; B{Decision}\n    B --&gt;|Yes| C[Continue]\n    B --&gt;|No| D[Stop]\n</code></pre> <pre><code>pie title Which animals do you prefer as pets?\n    \"Dogs\" : 386\n    \"Cats\" : 85\n    \"Rabbits\" : 53\n    \"Hamsters\" : 101\n</code></pre>"},{"location":"resources/#why-its-useful-in-ift3150","title":"Why it's useful in IFT3150:","text":"<p>For computer science projects, visualizing algorithms, data flow, or system architecture is key. Mermaid lets students easily include diagrams without needing external images.</p>"},{"location":"resources/#pymdown-extensions","title":"\u2705 <code>pymdown-extensions</code>","text":"<p>This is a collection of enhanced Markdown extensions, mostly used with Material for MkDocs. It enables:</p> <ul> <li>Better code highlighting with <code>superfences</code></li> <li>Tabs in Markdown (<code>tabbed</code>)</li> <li>Collapsible sections (<code>details</code>)</li> <li>Checkboxes for task lists (<code>tasklist</code>)</li> <li>Emoji support</li> <li>Keyboard key notation (<code>keys</code>)</li> <li>And many more UX-friendly features</li> </ul>"},{"location":"resources/#example-use-cases","title":"\ud83d\udd27 Example use cases:","text":"Python <pre><code>def hello():\n    print(\"Hello, world!\")\n</code></pre> Java <pre><code>public class Hello {\n    public static void main(String[] args) {\n        System.out.println(\"Hello, world!\");\n    }\n}\n</code></pre> <p>Note</p> <p>This is an important note for the reader.</p>"},{"location":"results/","title":"R\u00e9sultats","text":""},{"location":"results/#fonctionnalites","title":"Fonctionnalit\u00e9s","text":"<ul> <li>D\u00e9crire les fonctionnalit\u00e9s impl\u00e9ment\u00e9es.</li> </ul>"},{"location":"results/#demonstration","title":"D\u00e9monstration","text":"<ul> <li>Inclure des captures d'\u00e9cran ou des d\u00e9monstrations du syst\u00e8me.</li> </ul>"},{"location":"results/#bilan","title":"Bilan","text":"<ul> <li>\u00c9valuer la r\u00e9alisation des objectifs initiaux.</li> </ul>"},{"location":"suivi/","title":"Suivi de projet","text":""},{"location":"suivi/#semaine-1","title":"Semaine 1","text":"Mettre en place l'environnement <ul> <li> Lorem ipsum dolor sit amet, consectetur adipiscing elit</li> <li> Vestibulum convallis sit amet nisi a tincidunt<ul> <li> In hac habitasse platea dictumst</li> <li> In scelerisque nibh non dolor mollis congue sed et metus</li> <li> Praesent sed risus massa</li> </ul> </li> <li> Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque</li> </ul> <p>Notes</p> <ul> <li>Il est possible que nous r\u00e9visions les exigences apr\u00e8s le prototypage</li> </ul> <p>Difficult\u00e9s rencontr\u00e9es</p> <ul> <li>Le plugin Mermaid n'\u00e9tait pas reconnu : confusion entre <code>mkdocs-mermaid2-plugin</code> (pip) et <code>mermaid2</code> (plugin name)<ul> <li>R\u00e9solu apr\u00e8s nettoyage et configuration correcte dans <code>mkdocs.yml</code></li> </ul> </li> </ul> <p>Prochaines \u00e9tapes</p> <ul> <li>D\u00e9marrer l\u2019analyse du probl\u00e8me</li> <li>Cr\u00e9er la structure de <code>etudes_preliminaires.md</code></li> </ul>"},{"location":"suivi/#semaine-2","title":"Semaine 2","text":""},{"location":"suivi/#etablir-une-bonne-base-pour-la-comprehension-theorique-du-projet","title":"\u00c9tablir une bonne base pour la compr\u00e9hension th\u00e9orique du projet","text":"<ul> <li>Tutoriel sur les bases du brain encoding-decoding, tutorial</li> <li>Tutoriel sur le Graph Convolutional Network (GCN), tutorial</li> <li>Tutorial du Algonauts project 2025, tutorial</li> <li>Article \u00e0 lire/lu :<ul> <li> Functional annotation of human cognitive states using deep graph convolution</li> <li> Scaling up ridge regression for brain encoding in a massive individual fMRI dataset</li> <li> Brain decoding of the human connectome project tasks in a dense individual fMRI dataset</li> </ul> </li> </ul>"},{"location":"suivi/#semaine-3","title":"Semaine 3","text":""},{"location":"suivi/#semaine-4","title":"Semaine 4","text":""},{"location":"suivi/#semaine-5","title":"Semaine 5","text":""},{"location":"suivi/#semaine-6","title":"Semaine 6","text":""},{"location":"suivi/#semaine-7","title":"Semaine 7","text":""},{"location":"suivi/#semaine-8","title":"Semaine 8","text":""},{"location":"suivi/#semaine-9","title":"Semaine 9","text":""},{"location":"suivi/#semaine-10","title":"Semaine 10","text":""},{"location":"suivi/#semaine-11","title":"Semaine 11","text":""},{"location":"suivi/#semaine-12","title":"Semaine 12","text":""},{"location":"suivi/#semaine-13","title":"Semaine 13","text":""}]}